{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from coin_ai.alignment.data import HPairDataset, HomographyBatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_corners(homography_batch: HomographyBatch):\n",
    "    assert homography_batch.B == 1\n",
    "\n",
    "    fig, (a1, a2) = plt.subplots(1, 2)\n",
    "    im1, im2 = homography_batch.images.squeeze(1).permute(0, 2, 3, 1).cpu().numpy()\n",
    "    a1.imshow(im1)\n",
    "    a2.imshow(im2)\n",
    "\n",
    "    corners_base = homography_batch.corners.squeeze(0).cpu().numpy()\n",
    "    corners_base = corners_base / 2 + 128\n",
    "    corners_base = np.concatenate([corners_base, np.ones((4, 1))], axis=1)\n",
    "    corners_warp = corners_base @ homography_batch.H_12.squeeze(0).cpu().numpy().T\n",
    "\n",
    "    corners_warp /= corners_warp[:, 2:]\n",
    "    a2.plot(corners_warp[:, 0], corners_warp[:, 1], 'ro')\n",
    "    a1.plot(corners_base[:, 0], corners_base[:, 1], 'ro')\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import ConcatDataset, DataLoader\n",
    "import glob\n",
    "\n",
    "def assemble_datasets(path: str) -> ConcatDataset:\n",
    "    paths = glob.glob(f\"{path}/**/homographies.csv\", recursive=True)\n",
    "\n",
    "    datasets = [HPairDataset(path) for path in paths]\n",
    "    return ConcatDataset(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_ds = assemble_datasets('/Users/jatentaki/Data/archeo/coins/krzywousty-homographies')\n",
    "dataloader = DataLoader(concat_ds, batch_size=8, shuffle=True, collate_fn=HPairDataset.collate_fn)\n",
    "print(len(concat_ds))\n",
    "batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resized = batch.build_augmentation().resize((256, 256)).build()\n",
    "builder = batch.build_augmentation()\n",
    "with_aug = builder.apply(batch.get_alignment_transform()).build()#.apply(builder.random_h_4_point(scale=0.025)).build()\n",
    "#with_aug = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(with_aug.B):\n",
    "    fig = draw_corners(with_aug.slice(i, i + 1))\n",
    "    #fig.suptitle(f\"{i}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Callable\n",
    "\n",
    "import torch\n",
    "from einops import rearrange, repeat\n",
    "from torch import nn, Tensor\n",
    "\n",
    "from coin_ai.alignment.infra import DenseDino\n",
    "\n",
    "@dataclass\n",
    "class HCorrespondences:\n",
    "    corners_a: Tensor # B x 4 x 2\n",
    "    corners_b: Tensor # B x 4 x 2\n",
    "\n",
    "def homography_loss(homography_batch: HomographyBatch, model: Callable[[Tensor, ], HCorrespondences]) -> Tensor:\n",
    "    t, b, c, h, w = homography_batch.images.shape\n",
    "    norm = torch.tensor([w, h, 1], dtype=torch.float32, device=homography_batch.images.device).view(1, 3, 1)\n",
    "    H_12_norm = homography_batch.H_12 / norm\n",
    "\n",
    "    predictions = model(homography_batch.images)\n",
    "    corners_a_h = torch.cat([predictions.corners_a, torch.ones(1, 4, 1, device=H_12_norm.device)], dim=-1)\n",
    "\n",
    "    corners_b_gt = (corners_a_h @ H_12_norm.mT)[..., :2]\n",
    "\n",
    "    return nn.functional.mse_loss(predictions.corners_b, corners_b_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryInit(nn.Module):\n",
    "    def __init__(self, d_memory: int, d_target: int):\n",
    "        super().__init__()\n",
    "        self.n_heads = 8\n",
    "        self.q = nn.Parameter(torch.randn(self.n_heads, 4, d_memory))\n",
    "        self.v = nn.Linear(d_memory, d_target)\n",
    "        self.o = nn.Linear(d_target, d_target)\n",
    "\n",
    "    def forward(self, src_features: Tensor) -> Tensor:\n",
    "        b, n, c = src_features.shape\n",
    "        q = repeat(self.q, 'h q c -> b h q c', b=b)\n",
    "        k = rearrange(src_features, 'b n c -> b 1 n c') # full attention\n",
    "        v = rearrange(self.v(src_features), 'b n (h c) -> b h n c', h=self.n_heads)\n",
    "        queries = nn.functional.scaled_dot_product_attention(q, k, v)\n",
    "        return self.o(rearrange(queries, 'b h n c -> b n (h c)'))\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, d_io: int, d_ff: int | None = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if d_ff is None:\n",
    "            d_ff = 4 * d_io\n",
    "\n",
    "        self.fc1 = nn.Linear(d_io, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_io)\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.fc2(nn.functional.gelu(self.fc1(x)))\n",
    "    \n",
    "class CrossAttention(nn.Module):\n",
    "    def __init__(self, d_src: int, d_tgt: int, n_heads: int):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.q = nn.Linear(d_tgt, d_tgt)\n",
    "        self.kv = nn.Linear(d_src, 2 * d_tgt)\n",
    "        self.o = nn.Linear(d_tgt, d_tgt)\n",
    "    \n",
    "    def forward(self, target: Tensor, memory: Tensor) -> Tensor:\n",
    "        b, q, c = target.shape\n",
    "\n",
    "        q = rearrange(self.q(target), 'b q (h c) -> b h q c', h=self.n_heads)\n",
    "        k, v = rearrange(self.kv(memory), 'b n (t h c) -> t b h n c', h=self.n_heads, t=2)\n",
    "\n",
    "        out = nn.functional.scaled_dot_product_attention(q, k, v)\n",
    "        return self.o(rearrange(out, 'b h n c -> b n (h c)'))\n",
    "\n",
    "class CrossAttentionBlock(nn.Module):\n",
    "    def __init__(self, d_memory: int, d_target: int, n_heads: int, d_ff: int | None = None):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(d_target)\n",
    "        self.cross_attention = CrossAttention(d_src=d_memory, d_tgt=d_target, n_heads=n_heads)\n",
    "        self.norm2 = nn.LayerNorm(d_target)\n",
    "        self.mlp = MLP(d_target, d_ff)\n",
    "    \n",
    "    def forward(self, queries: Tensor, memory: Tensor) -> Tensor:\n",
    "        q = queries\n",
    "        q = q + self.cross_attention(self.norm1(q), memory)\n",
    "        q = q + self.mlp(self.norm2(q))\n",
    "        return q\n",
    "\n",
    "class HFormer(nn.Module):\n",
    "    def __init__(self, n_layers: int = 3, d_target: int = 128, deformation_scale: float = 0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dino = DenseDino()\n",
    "        self.dino.requires_grad_(False)\n",
    "        d_memory = 384\n",
    "        self.n_heads = 8\n",
    "        self.query_init = QueryInit(d_memory=d_memory, d_target=d_target)\n",
    "        self.attn_blocks = nn.ModuleList([\n",
    "            CrossAttentionBlock(d_memory=d_memory, d_target=d_target, n_heads=self.n_heads)\n",
    "            for _ in range(2 * n_layers - 1)\n",
    "        ])\n",
    "\n",
    "        self.final_norm = nn.LayerNorm(d_target)\n",
    "        self.xy_head = nn.Linear(d_target, 2, bias=False)\n",
    "\n",
    "        self.register_buffer(\n",
    "            'corners_a',\n",
    "            torch.tensor([\n",
    "                [0., 0.],\n",
    "                [1., 0.],\n",
    "                [1., 1.],\n",
    "                [0., 1.]\n",
    "            ], dtype=torch.float32).reshape(1, 4, 2),\n",
    "        )\n",
    "        self.deformation_scale = deformation_scale\n",
    "    \n",
    "    def forward(self, images: Tensor) -> HCorrespondences:\n",
    "        src_feat, dst_feat = self._get_features(images)\n",
    "        q = self.query_init(src_feat)\n",
    "\n",
    "        for i, block in enumerate(self.attn_blocks):\n",
    "            if i % 2 == 0:\n",
    "                memory = dst_feat\n",
    "            else:\n",
    "                memory = src_feat\n",
    "\n",
    "            q = block(q, memory)\n",
    "        \n",
    "        offset = torch.tanh(self.xy_head(self.final_norm(q)))\n",
    "\n",
    "        corners_b = self.corners_a + self.deformation_scale * offset\n",
    "        return HCorrespondences(corners_a=self.corners_a, corners_b=corners_b)\n",
    "    \n",
    "    def _get_features(self, images: Tensor) -> tuple[Tensor, Tensor]:\n",
    "        \"\"\"\n",
    "        Images: 2 x B x C x H x W\n",
    "        \n",
    "        Returns:\n",
    "            src_feat: B x N x C\n",
    "            dst_feat: B x N x C\n",
    "        \"\"\"\n",
    "        t, b, c, h, w = images.shape\n",
    "        assert t == 2\n",
    "        assert c == 3\n",
    "\n",
    "        images_flat = rearrange(images, 't b c h w -> (t b) c h w')\n",
    "        with torch.no_grad():\n",
    "            features_flat: Tensor = self.dino(images_flat)\n",
    "        src_feat, dst_feat = rearrange(features_flat, '(t b) h w c -> t b (h w) c', b=b, t=2)\n",
    "        return src_feat, dst_feat\n",
    "\n",
    "    def loss_fn(self, homography_batch: HomographyBatch) -> Tensor:\n",
    "        return homography_loss(homography_batch, self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('mps')\n",
    "hformer = HFormer().to(device)\n",
    "optim = torch.optim.AdamW(hformer.parameters(), lr=1e-4, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = sum(p.numel() for p in hformer.parameters() if p.requires_grad)\n",
    "print(f\"{n:,} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dataloader:\n",
    "    optim.zero_grad()\n",
    "    batch = batch.to(device)\n",
    "    loss = hformer.loss_fn(batch)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    print(loss.item())\n",
    "\n",
    "    if loss.item() < 0.01:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
