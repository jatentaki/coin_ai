{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from coin_ai.data.inference import InferenceImageDataset, ResizeAndKeepRatio\n",
    "from coin_ai.augmentations import CircleCrop\n",
    "from coin_ai.config import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_root = 'checkpoints/24.02.20/attn-readout-rotations-flips'\n",
    "data_root = '/Users/jatentaki/Data/archeo/coins/FMP/slices-high-res/just_coins'\n",
    "embedding_save_name = f'{config_root}/embeddings.pt'\n",
    "version = 0\n",
    "config = load_config(f'{config_root}/config.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = config.learner\n",
    "state_dict = torch.load(f'{config_root}/lightning_logs/version_{version}/checkpoints/val_1_acc_at_1.ckpt', map_location='cpu')['state_dict']\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.val_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    ResizeAndKeepRatio(518),\n",
    "    CircleCrop(518),\n",
    "    config.val_augmentation,\n",
    "])\n",
    "\n",
    "dataset = InferenceImageDataset(data_root, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, names = next(iter(dataloader))\n",
    "\n",
    "fig, axes = plt.subplots(4, 4, figsize=(10, 10))\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.imshow(images[i].permute(1, 2, 0))\n",
    "    ax.set_title(names[i])\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference():\n",
    "    device = torch.device('mps')\n",
    "    model = model.to(device)\n",
    "\n",
    "    embeddings, names = [], []\n",
    "    for batch_images, batch_names in tqdm(dataloader):\n",
    "        batch_images = batch_images.to(device)\n",
    "        with torch.inference_mode():\n",
    "            out = model(batch_images)\n",
    "        \n",
    "        embeddings.append(out.cpu())\n",
    "        names.extend(batch_names)\n",
    "\n",
    "    embeddings = torch.cat(embeddings)\n",
    "\n",
    "    torch.save({'embeddings': embeddings, 'names': names}, embedding_save_name)\n",
    "\n",
    "#run_inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_state = torch.load(embedding_save_name)\n",
    "embeddings = _state['embeddings']\n",
    "names = _state['names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = config.loss_fn.similarity\n",
    "all_to_all = similarity(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_ix = torch.arange(all_to_all.shape[0])\n",
    "all_to_all[diag_ix, diag_ix] = -1.\n",
    "all_to_all = torch.tril(all_to_all, diagonal=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_to_all_flat = all_to_all.flatten()\n",
    "_, top_ix = all_to_all_flat.topk(1000)\n",
    "top_i, top_j = top_ix // all_to_all.shape[0], top_ix % all_to_all.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in zip(top_i[:25], top_j):\n",
    "    fig, (a1, a2) = plt.subplots(1, 2)\n",
    "    a1.imshow(dataset.load_by_name(names[i]).permute(1, 2, 0))\n",
    "    a1.set_title(names[i])\n",
    "    a1.axis('off')\n",
    "    a2.imshow(dataset.load_by_name(names[j]).permute(1, 2, 0))\n",
    "    a2.set_title(names[j])\n",
    "    a2.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_examples = 64\n",
    "# #rng = torch.Generator().manual_seed(42)\n",
    "# #indices = torch.randperm(len(embeddings), generator=rng)[:n_examples]\n",
    "# indices = torch.arange(n_examples)\n",
    "# example_names = [names[i] for i in indices]\n",
    "# #example_images = [dataset.load_by_name(name) for name in example_names]\n",
    "# example_embeddings = embeddings[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from dataclasses import dataclass\n",
    "# @dataclass\n",
    "# class SimilarCoin:\n",
    "#     file_name: str\n",
    "#     similarity: float\n",
    "\n",
    "#     def load_image(self) -> Tensor:\n",
    "#         return dataset.load_by_name(self.file_name).permute(1, 2, 0)\n",
    "\n",
    "# @dataclass\n",
    "# class SimilarSeries:\n",
    "#     example: str\n",
    "#     similar_coins: list[SimilarCoin]\n",
    "\n",
    "#     @classmethod\n",
    "#     def from_values_and_indices(cls, example: str, values: Tensor, indices: Tensor) -> \"SimilarSeries\":\n",
    "#         similar_coins = [SimilarCoin(names[i], v.item()) for i, v in zip(indices, values)]\n",
    "#         return cls(example, similar_coins)\n",
    "\n",
    "#     def plot(self):\n",
    "#         n_similar = len(self.similar_coins)\n",
    "#         nearest_square = int(n_similar ** 0.5)\n",
    "\n",
    "#         fig, axes = plt.subplots(nearest_square, nearest_square, figsize=(20, 20), tight_layout=True)\n",
    "#         for ax, coin in zip(axes.flat, self.similar_coins):\n",
    "#             ax.imshow(coin.load_image())\n",
    "#             coin_id = coin.file_name.removesuffix('.png')\n",
    "#             ax.set_title(f\"{coin_id}\\n({coin.similarity:.2f})\")\n",
    "#             ax.axis('off')\n",
    "        \n",
    "#         return fig\n",
    "\n",
    "# similarities = similarity(example_embeddings, embeddings)\n",
    "# values, similar_indices = similarities.topk(25, dim=-1)\n",
    "\n",
    "# series = []\n",
    "# for example, value, indices in zip(example_names, values, similar_indices):\n",
    "#     series.append(SimilarSeries.from_values_and_indices(example, value, indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for s in series:\n",
    "#     fig = s.plot()\n",
    "#     fig.savefig(f'similarity_tables/{s.example}')\n",
    "#     plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
